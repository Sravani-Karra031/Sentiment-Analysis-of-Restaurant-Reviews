{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "570c84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d3f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV Dataset file\n",
    "df = pd.read_csv('Restaurant_Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c63128e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feb8f9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Review', 'Liked'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d909087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "695e8384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee575259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  1000 non-null   object\n",
      " 1   Liked   1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e23067d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    0\n",
       "Liked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2a8400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: Liked, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Liked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b37a8c",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad7a76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked  Length\n",
       "0                           Wow... Loved this place.      1      24\n",
       "1                                 Crust is not good.      0      18\n",
       "2          Not tasty and the texture was just nasty.      0      41\n",
       "3  Stopped by during the late May bank holiday of...      1      87\n",
       "4  The selection on the menu was great and so wer...      1      59"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Length'] = df['Review'].apply(len)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f3997",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "646e9ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\KARRA\n",
      "[nltk_data]     TEJASWINIREDDY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing the NLP Libraries\n",
    "import nltk\n",
    "import re\n",
    "# Download NLTK stopwords data\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98133f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(list(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46ab0a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdf3f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "corpus = []\n",
    "\n",
    "# Loop through each review\n",
    "for i in range(len(df)):\n",
    "    # Clean and preprocess the review\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['Review'][i])  # Remove non-alphabetical characters\n",
    "    review = review.lower()  # Convert text to lowercase\n",
    "    review_words = review.split()  # Tokenization\n",
    "    review_words = [word for word in review_words if word not in set(stopwords.words('english'))]  # Remove Stop Words\n",
    "    review_words = [stemmer.stem(word) for word in review_words]  # Stemming\n",
    "    review = ' '.join(review_words)  # Rejoin Tokens\n",
    "    corpus.append(review)  # Append to Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eedad33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow love place',\n",
       " 'crust good',\n",
       " 'tasti textur nasti',\n",
       " 'stop late may bank holiday rick steve recommend love',\n",
       " 'select menu great price',\n",
       " 'get angri want damn pho',\n",
       " 'honeslti tast fresh',\n",
       " 'potato like rubber could tell made ahead time kept warmer',\n",
       " 'fri great',\n",
       " 'great touch']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ceacc",
   "metadata": {},
   "source": [
    "# Creating a Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b44de209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(max_features=1500, min_df=2)\n",
    "x = tf.fit_transform(corpus).toarray() # Transform the text data into TF-IDF features\n",
    "X = tf.fit_transform(corpus).toarray()\n",
    "y = df['Liked'].values\n",
    "# y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291d058d",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e04f99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d054a59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 693), (200, 693), (800,), (200,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f4057",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d816497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-1 : Random Forest\n",
      "Training Accuracy: 79.98%\n",
      "Testing Accuracy: 74.21%\n",
      "Accuracy Difference: 2.65%\n",
      "model-2 : SVC\n",
      "Training Accuracy: 79.62%\n",
      "Testing Accuracy: 78.00%\n",
      "Accuracy Difference: 1.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import train_test_split, KFold\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=6, min_samples_split=4, min_samples_leaf=2, random_state=42)\n",
    "num_folds = 11\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=41)\n",
    "\n",
    "# Lists to store accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Loop through k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    #model\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    accuracy_diff = abs(train_accuracy - test_accuracy)\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "# # Split the data with the same random seed for consistency\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=41)\n",
    "\n",
    "classifier = SVC(kernel='linear', C=0.1, random_state=42)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(x_test)\n",
    "y_train_pred = classifier.predict(x_train)\n",
    "\n",
    "# Calculate the average training and testing accuracies\n",
    "average_train_accuracy = np.mean(train_accuracies)\n",
    "average_test_accuracy = np.mean(test_accuracies)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"model-1 : Random Forest\") #random forest\n",
    "print(f\"Training Accuracy: {average_train_accuracy * 100:.2f}%\")\n",
    "print(f\"Testing Accuracy: {average_test_accuracy * 100:.2f}%\")\n",
    "print(\"Accuracy Difference: {:.2f}%\".format(accuracy_diff * 100))\n",
    "\n",
    "\n",
    "\n",
    "    # Evaluate the model\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_diff = abs(train_accuracy - test_accuracy)\n",
    "\n",
    "    # Print the results\n",
    "print(\"model-2 : SVC\")\n",
    "print(\"Training Accuracy: {:.2f}%\".format(train_accuracy * 100))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
    "print(\"Accuracy Difference: {:.2f}%\".format(accuracy_diff * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "464200a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.81       103\n",
      "           1       0.88      0.63      0.73        97\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.80      0.78      0.77       200\n",
      "weighted avg       0.80      0.78      0.77       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b1562fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: 'The food is really bad.'\n",
      "Sentiment: NEGATIVE\n",
      "\n",
      "Review: 'I love their delicious dishes!'\n",
      "Sentiment: POSITIVE\n",
      "\n",
      "Review: 'Terrible experience. Avoid this place.'\n",
      "Sentiment: NEGATIVE\n",
      "\n",
      "Review: 'The service was excellent.'\n",
      "Sentiment: POSITIVE\n",
      "\n",
      "Review: 'Worst place ever, but nice food'\n",
      "Sentiment: NEGATIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(sample_review, classifier, tf):\n",
    "    # Preprocess the sample review\n",
    "    sample_review = re.sub(pattern='[^a-zA-Z]', repl=' ', string=sample_review)\n",
    "    sample_review = sample_review.lower()\n",
    "    sample_review_words = sample_review.split()\n",
    "    sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]\n",
    "    ps = PorterStemmer()\n",
    "    final_review = [ps.stem(word) for word in sample_review_words]\n",
    "    final_review = ' '.join(final_review)\n",
    "    \n",
    "    temp = tf.transform([final_review]).toarray()\n",
    "\n",
    "    # Use the pre-trained classifier to predict sentiment\n",
    "    sentiment = classifier.predict(temp)\n",
    "\n",
    "    # Post-processing: Check for positive words\n",
    "    positive_words = [\"good\", \"excellent\", \"amazing\", \"delicious\"]  # Add more positive words as needed\n",
    "    for word in positive_words:\n",
    "        if word in sample_review.lower():\n",
    "            sentiment = [1]  # Override sentiment to positive\n",
    "\n",
    "    return sentiment[0]\n",
    "\n",
    "# Sample reviews as strings\n",
    "reviews = [\n",
    "    'The food is really bad.',\n",
    "    'I love their delicious dishes!',\n",
    "    'Terrible experience. Avoid this place.',\n",
    "    'The service was excellent.',\n",
    "    'Worst place ever, but nice food'\n",
    "]\n",
    "\n",
    "# Assuming you have already defined the 'predict_sentiment' function, classifier, and tf\n",
    "\n",
    "for review in reviews:\n",
    "    sentiment = predict_sentiment(review, classifier, tf)\n",
    "    if sentiment:\n",
    "        sentiment_label = 'POSITIVE'\n",
    "    else:\n",
    "        sentiment_label = 'NEGATIVE'\n",
    "\n",
    "    print(f\"Review: '{review}'\")\n",
    "    print(f\"Sentiment: {sentiment_label}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e0c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
